{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2a2b11",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/sahil/Dev/cdro/rnd/.venv/lib/python3.11/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <B111F8D5-6AC6-3245-A6B5-94693F6992AB> /Users/sahil/Dev/cdro/rnd/.venv/lib/python3.11/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLPRegressor\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Advanced models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlgb\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcb\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/cdro/rnd/.venv/lib/python3.11/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/cdro/rnd/.venv/lib/python3.11/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/cdro/rnd/.venv/lib/python3.11/site-packages/xgboost/core.py:308\u001b[39m\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m    314\u001b[39m \u001b[33;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m        return value from API calls\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/cdro/rnd/.venv/lib/python3.11/site-packages/xgboost/core.py:270\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[32m    269\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    271\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    279\u001b[39m \n\u001b[32m    280\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    281\u001b[39m \n\u001b[32m    282\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    284\u001b[39m         )\n\u001b[32m    285\u001b[39m     _register_log_callback(lib)\n\u001b[32m    287\u001b[39m     libver = _lib_version(lib)\n",
      "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/sahil/Dev/cdro/rnd/.venv/lib/python3.11/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <B111F8D5-6AC6-3245-A6B5-94693F6992AB> /Users/sahil/Dev/cdro/rnd/.venv/lib/python3.11/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "# Regression Model Analysis for Sales Qty Prediction\n",
    "# Comprehensive model comparison with hyperparameter tuning\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score, \n",
    "                           median_absolute_error, max_error, explained_variance_score)\n",
    "\n",
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Advanced models\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"LightGBM version: {lgb.__version__}\")\n",
    "print(f\"CatBoost version: {cb.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training and Test Data\n",
    "print(\"Loading training and test data...\")\n",
    "\n",
    "# Load training data (2022-2024)\n",
    "train_data = pd.read_csv('chennai_1.5_5_star_monthly_data.csv')\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "\n",
    "# Load test data (2025)\n",
    "test_data = pd.read_csv('chennai_1.5_5_star_monthly_data_test.csv')\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"\\n=== TRAINING DATA INFO ===\")\n",
    "print(train_data.info())\n",
    "print(\"\\n=== TRAINING DATA HEAD ===\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\n=== TEST DATA INFO ===\")\n",
    "print(test_data.info())\n",
    "print(\"\\n=== TEST DATA HEAD ===\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "print(\"Training data missing values:\")\n",
    "print(train_data.isnull().sum())\n",
    "print(\"\\nTest data missing values:\")\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n=== TRAINING DATA STATISTICS ===\")\n",
    "print(train_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc039056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "print(\"=== EXPLORATORY DATA ANALYSIS ===\")\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create subplots for EDA\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Exploratory Data Analysis - Training Data', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Sales Qty over time\n",
    "axes[0, 0].plot(train_data['YearMonth'], train_data['Sales Qty.'], marker='o', linewidth=2)\n",
    "axes[0, 0].set_title('Sales Qty Over Time')\n",
    "axes[0, 0].set_xlabel('Year-Month')\n",
    "axes[0, 0].set_ylabel('Sales Qty')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Sales Qty distribution\n",
    "axes[0, 1].hist(train_data['Sales Qty.'], bins=15, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Sales Qty Distribution')\n",
    "axes[0, 1].set_xlabel('Sales Qty')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# 3. Temperature vs Sales\n",
    "axes[0, 2].scatter(train_data['Max_Temp'], train_data['Sales Qty.'], alpha=0.6)\n",
    "axes[0, 2].set_title('Max Temperature vs Sales Qty')\n",
    "axes[0, 2].set_xlabel('Max Temperature (°C)')\n",
    "axes[0, 2].set_ylabel('Sales Qty')\n",
    "\n",
    "# 4. Humidity vs Sales\n",
    "axes[1, 0].scatter(train_data['Humidity'], train_data['Sales Qty.'], alpha=0.6, color='green')\n",
    "axes[1, 0].set_title('Humidity vs Sales Qty')\n",
    "axes[1, 0].set_xlabel('Humidity (%)')\n",
    "axes[1, 0].set_ylabel('Sales Qty')\n",
    "\n",
    "# 5. Season vs Sales\n",
    "season_names = {0: 'Autumn', 1: 'Spring', 2: 'Summer', 3: 'Winter'}\n",
    "train_data['Season_Name'] = train_data['Season_encoded'].map(season_names)\n",
    "season_sales = train_data.groupby('Season_Name')['Sales Qty.'].mean()\n",
    "axes[1, 1].bar(season_sales.index, season_sales.values, alpha=0.7)\n",
    "axes[1, 1].set_title('Average Sales by Season')\n",
    "axes[1, 1].set_xlabel('Season')\n",
    "axes[1, 1].set_ylabel('Average Sales Qty')\n",
    "\n",
    "# 6. Correlation heatmap\n",
    "correlation_features = ['Sales Qty.', 'Max_Temp', 'Min_Temp', 'Humidity', 'Wind_Speed', 'Population_Millions', 'Season_encoded']\n",
    "corr_matrix = train_data[correlation_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1, 2])\n",
    "axes[1, 2].set_title('Feature Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlation with target\n",
    "print(\"\\n=== CORRELATION WITH SALES QTY ===\")\n",
    "correlations = train_data[correlation_features].corr()['Sales Qty.'].sort_values(ascending=False)\n",
    "print(correlations)\n",
    "\n",
    "# Seasonal analysis\n",
    "print(\"\\n=== SEASONAL ANALYSIS ===\")\n",
    "seasonal_stats = train_data.groupby('Season_Name')['Sales Qty.'].agg(['count', 'mean', 'std', 'min', 'max'])\n",
    "print(seasonal_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"=== FEATURE ENGINEERING ===\")\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create engineered features from the dataset\n",
    "    \"\"\"\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    # Convert YearMonth to datetime\n",
    "    df_eng['YearMonth'] = pd.to_datetime(df_eng['YearMonth'])\n",
    "    \n",
    "    # Extract temporal features\n",
    "    df_eng['Year'] = df_eng['YearMonth'].dt.year\n",
    "    df_eng['Month'] = df_eng['YearMonth'].dt.month\n",
    "    df_eng['Quarter'] = df_eng['YearMonth'].dt.quarter\n",
    "    \n",
    "    # Create temperature range feature\n",
    "    df_eng['Temp_Range'] = df_eng['Max_Temp'] - df_eng['Min_Temp']\n",
    "    \n",
    "    # Create temperature average\n",
    "    df_eng['Avg_Temp'] = (df_eng['Max_Temp'] + df_eng['Min_Temp']) / 2\n",
    "    \n",
    "    # Create weather comfort index (lower is more comfortable)\n",
    "    df_eng['Weather_Comfort'] = (df_eng['Max_Temp'] * 0.3 + \n",
    "                                df_eng['Humidity'] * 0.3 + \n",
    "                                df_eng['Wind_Speed'] * 0.2 + \n",
    "                                df_eng['Temp_Range'] * 0.2)\n",
    "    \n",
    "    # Create population density proxy (assuming constant area)\n",
    "    df_eng['Population_Density'] = df_eng['Population_Millions']  # Already in millions\n",
    "    \n",
    "    return df_eng\n",
    "\n",
    "# Apply feature engineering to both datasets\n",
    "print(\"Creating engineered features...\")\n",
    "train_eng = create_features(train_data)\n",
    "test_eng = create_features(test_data)\n",
    "\n",
    "# Display new features\n",
    "print(f\"Training data shape after feature engineering: {train_eng.shape}\")\n",
    "print(f\"Test data shape after feature engineering: {test_eng.shape}\")\n",
    "\n",
    "# Show new columns\n",
    "new_features = ['Year', 'Month', 'Quarter', 'Temp_Range', 'Avg_Temp', 'Weather_Comfort', 'Population_Density']\n",
    "print(f\"\\nNew features created: {new_features}\")\n",
    "\n",
    "# Display sample of engineered data\n",
    "print(\"\\n=== ENGINEERED FEATURES SAMPLE ===\")\n",
    "print(train_eng[['YearMonth', 'Sales Qty.', 'Max_Temp', 'Min_Temp', 'Temp_Range', 'Avg_Temp', 'Weather_Comfort']].head())\n",
    "\n",
    "# Check for any infinite or NaN values in new features\n",
    "print(\"\\n=== CHECKING FOR DATA QUALITY ISSUES ===\")\n",
    "for feature in new_features:\n",
    "    if feature in train_eng.columns:\n",
    "        inf_count = np.isinf(train_eng[feature]).sum()\n",
    "        nan_count = train_eng[feature].isnull().sum()\n",
    "        print(f\"{feature}: {inf_count} infinite values, {nan_count} NaN values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9026a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Features and Target Variables\n",
    "print(\"=== PREPARING FEATURES AND TARGET ===\")\n",
    "\n",
    "# Define features to use (excluding Sales_Per_Capita to avoid data leakage)\n",
    "base_features = ['Max_Temp', 'Min_Temp', 'Humidity', 'Wind_Speed', 'Population_Millions', 'Season_encoded']\n",
    "engineered_features = ['Year', 'Month', 'Quarter', 'Temp_Range', 'Avg_Temp', 'Weather_Comfort', 'Population_Density']\n",
    "\n",
    "# Combine all features\n",
    "all_features = base_features + engineered_features\n",
    "\n",
    "print(f\"Base features: {base_features}\")\n",
    "print(f\"Engineered features: {engineered_features}\")\n",
    "print(f\"Total features: {len(all_features)}\")\n",
    "\n",
    "# Prepare training data\n",
    "X_train_base = train_eng[base_features].values\n",
    "X_train_eng = train_eng[all_features].values\n",
    "y_train = train_eng['Sales Qty.'].values\n",
    "\n",
    "# Prepare test data\n",
    "X_test_base = test_eng[base_features].values\n",
    "X_test_eng = test_eng[all_features].values\n",
    "y_test = test_eng['Sales Qty.'].values\n",
    "\n",
    "print(f\"\\nTraining data shapes:\")\n",
    "print(f\"X_train_base: {X_train_base.shape}\")\n",
    "print(f\"X_train_eng: {X_train_eng.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "print(f\"\\nTest data shapes:\")\n",
    "print(f\"X_test_base: {X_test_base.shape}\")\n",
    "print(f\"X_test_eng: {X_test_eng.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# Create feature names for reference\n",
    "feature_names_base = base_features\n",
    "feature_names_eng = all_features\n",
    "\n",
    "print(f\"\\nFeature names (base): {feature_names_base}\")\n",
    "print(f\"Feature names (engineered): {feature_names_eng}\")\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\n=== DATA QUALITY CHECK ===\")\n",
    "print(f\"Training data missing values: {np.isnan(X_train_eng).sum()}\")\n",
    "print(f\"Test data missing values: {np.isnan(X_test_eng).sum()}\")\n",
    "print(f\"Target missing values (train): {np.isnan(y_train).sum()}\")\n",
    "print(f\"Target missing values (test): {np.isnan(y_test).sum()}\")\n",
    "\n",
    "# Display target variable statistics\n",
    "print(f\"\\n=== TARGET VARIABLE STATISTICS ===\")\n",
    "print(f\"Training target - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}\")\n",
    "print(f\"Training target - Min: {y_train.min():.2f}, Max: {y_train.max():.2f}\")\n",
    "print(f\"Test target - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")\n",
    "print(f\"Test target - Min: {y_test.min():.2f}, Max: {y_test.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Scaling\n",
    "print(\"=== PREPROCESSING AND SCALING ===\")\n",
    "\n",
    "# Create scalers for both base and engineered features\n",
    "scaler_base = StandardScaler()\n",
    "scaler_eng = StandardScaler()\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_base_scaled = scaler_base.fit_transform(X_train_base)\n",
    "X_train_eng_scaled = scaler_eng.fit_transform(X_train_eng)\n",
    "\n",
    "# Transform test data using fitted scalers\n",
    "X_test_base_scaled = scaler_base.transform(X_test_base)\n",
    "X_test_eng_scaled = scaler_eng.transform(X_test_eng)\n",
    "\n",
    "print(\"Data scaling completed successfully!\")\n",
    "print(f\"Scaled training data shapes:\")\n",
    "print(f\"X_train_base_scaled: {X_train_base_scaled.shape}\")\n",
    "print(f\"X_train_eng_scaled: {X_train_eng_scaled.shape}\")\n",
    "\n",
    "print(f\"\\nScaled test data shapes:\")\n",
    "print(f\"X_test_base_scaled: {X_test_base_scaled.shape}\")\n",
    "print(f\"X_test_eng_scaled: {X_test_eng_scaled.shape}\")\n",
    "\n",
    "# Verify scaling worked correctly\n",
    "print(f\"\\n=== SCALING VERIFICATION ===\")\n",
    "print(f\"Base features - Mean: {X_train_base_scaled.mean(axis=0).round(3)}\")\n",
    "print(f\"Base features - Std: {X_train_base_scaled.std(axis=0).round(3)}\")\n",
    "print(f\"Engineered features - Mean: {X_train_eng_scaled.mean(axis=0).round(3)}\")\n",
    "print(f\"Engineered features - Std: {X_train_eng_scaled.std(axis=0).round(3)}\")\n",
    "\n",
    "# Create polynomial features for comparison\n",
    "print(f\"\\n=== CREATING POLYNOMIAL FEATURES ===\")\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "\n",
    "# Create polynomial features for base features only (to avoid overfitting with small dataset)\n",
    "X_train_poly = poly_features.fit_transform(X_train_base_scaled)\n",
    "X_test_poly = poly_features.transform(X_test_base_scaled)\n",
    "\n",
    "print(f\"Polynomial features shape: {X_train_poly.shape}\")\n",
    "print(f\"Number of polynomial features: {X_train_poly.shape[1]}\")\n",
    "\n",
    "# Get polynomial feature names\n",
    "poly_feature_names = poly_features.get_feature_names_out(feature_names_base)\n",
    "print(f\"Polynomial feature names: {poly_feature_names}\")\n",
    "\n",
    "# Summary of all feature sets\n",
    "print(f\"\\n=== FEATURE SETS SUMMARY ===\")\n",
    "print(f\"1. Base features: {X_train_base_scaled.shape[1]} features\")\n",
    "print(f\"2. Engineered features: {X_train_eng_scaled.shape[1]} features\") \n",
    "print(f\"3. Polynomial features: {X_train_poly.shape[1]} features\")\n",
    "\n",
    "# We'll test all three feature sets in our models\n",
    "feature_sets = {\n",
    "    'base': (X_train_base_scaled, X_test_base_scaled, feature_names_base),\n",
    "    'engineered': (X_train_eng_scaled, X_test_eng_scaled, feature_names_eng),\n",
    "    'polynomial': (X_train_poly, X_test_poly, poly_feature_names)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2db71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models and Hyperparameter Grids\n",
    "print(\"=== DEFINING MODELS AND HYPERPARAMETER GRIDS ===\")\n",
    "\n",
    "# Define all models with their hyperparameter grids\n",
    "models_config = {\n",
    "    'LinearRegression': {\n",
    "        'model': LinearRegression(),\n",
    "        'grid_params': {},\n",
    "        'random_params': {}\n",
    "    },\n",
    "    \n",
    "    'Ridge': {\n",
    "        'model': Ridge(random_state=RANDOM_STATE),\n",
    "        'grid_params': {\n",
    "            'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Lasso': {\n",
    "        'model': Lasso(random_state=RANDOM_STATE, max_iter=2000),\n",
    "        'grid_params': {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'ElasticNet': {\n",
    "        'model': ElasticNet(random_state=RANDOM_STATE, max_iter=2000),\n",
    "        'grid_params': {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "            'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'SVR': {\n",
    "        'model': SVR(),\n",
    "        'grid_params': {\n",
    "            'C': [0.1, 1.0, 10.0, 100.0],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1.0],\n",
    "            'kernel': ['rbf', 'linear', 'poly']\n",
    "        },\n",
    "        'random_params': {\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "            'gamma': ['scale', 'auto', 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "            'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'DecisionTreeRegressor': {\n",
    "        'model': DecisionTreeRegressor(random_state=RANDOM_STATE),\n",
    "        'grid_params': {\n",
    "            'max_depth': [3, 5, 7, 10, None],\n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 8]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "            'min_samples_split': [2, 5, 10, 15, 20, 25],\n",
    "            'min_samples_leaf': [1, 2, 4, 6, 8, 10],\n",
    "            'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'RandomForestRegressor': {\n",
    "        'model': RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "        'grid_params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, 15, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'n_estimators': [50, 100, 200, 300, 500],\n",
    "            'max_depth': [5, 10, 15, 20, None],\n",
    "            'min_samples_split': [2, 5, 10, 15, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "            'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'GradientBoostingRegressor': {\n",
    "        'model': GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "        'grid_params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.8, 0.9, 1.0]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'n_estimators': [50, 100, 200, 300, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "            'max_depth': [3, 5, 7, 9, 11],\n",
    "            'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'XGBRegressor': {\n",
    "        'model': xgb.XGBRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "        'grid_params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.8, 0.9, 1.0]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'n_estimators': [50, 100, 200, 300, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "            'max_depth': [3, 5, 7, 9, 11],\n",
    "            'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'LGBMRegressor': {\n",
    "        'model': lgb.LGBMRegressor(random_state=RANDOM_STATE, n_jobs=-1, verbose=-1),\n",
    "        'grid_params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.8, 0.9, 1.0]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'n_estimators': [50, 100, 200, 300, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "            'max_depth': [3, 5, 7, 9, 11],\n",
    "            'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'CatBoostRegressor': {\n",
    "        'model': cb.CatBoostRegressor(random_state=RANDOM_STATE, verbose=False),\n",
    "        'grid_params': {\n",
    "            'iterations': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'depth': [3, 5, 7],\n",
    "            'subsample': [0.8, 0.9, 1.0]\n",
    "        },\n",
    "        'random_params': {\n",
    "            'iterations': [50, 100, 200, 300, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "            'depth': [3, 5, 7, 9, 11],\n",
    "            'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'MLPRegressor': {\n",
    "        'model': MLPRegressor(random_state=RANDOM_STATE, max_iter=1000),\n",
    "        'grid_params': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'alpha': [0.0001, 0.001, 0.01],\n",
    "            'learning_rate': ['constant', 'adaptive']\n",
    "        },\n",
    "        'random_params': {\n",
    "            'hidden_layer_sizes': [(25,), (50,), (100,), (50, 25), (100, 50), (50, 50), (100, 100)],\n",
    "            'activation': ['relu', 'tanh', 'logistic'],\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "            'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "            'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(models_config)} models:\")\n",
    "for model_name in models_config.keys():\n",
    "    print(f\"- {model_name}\")\n",
    "\n",
    "print(f\"\\nModels will be tested with:\")\n",
    "print(f\"- Default parameters\")\n",
    "print(f\"- GridSearchCV (5-fold cross-validation)\")\n",
    "print(f\"- RandomizedSearchCV (5-fold cross-validation, 50 iterations)\")\n",
    "print(f\"- Three feature sets: base, engineered, polynomial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation Functions\n",
    "print(\"=== SETTING UP TRAINING AND EVALUATION FUNCTIONS ===\")\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate comprehensive regression metrics\"\"\"\n",
    "    # Avoid division by zero in MAPE calculation\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), 1e-8))) * 100\n",
    "    \n",
    "    return {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'MAPE': mape,\n",
    "        'MedAE': median_absolute_error(y_true, y_pred),\n",
    "        'Max_Error': max_error(y_true, y_pred),\n",
    "        'Explained_Variance': explained_variance_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def train_and_evaluate_model(model, model_name, feature_set_name, X_train, X_test, y_train, y_test, \n",
    "                           grid_params=None, random_params=None):\n",
    "    \"\"\"Train and evaluate a model with different hyperparameter tuning methods\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # 1. Default parameters\n",
    "    print(f\"  Training {model_name} with default parameters...\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    model_default = model.__class__(**model.get_params())\n",
    "    model_default.fit(X_train, y_train)\n",
    "    y_pred_default = model_default.predict(X_test)\n",
    "    \n",
    "    default_metrics = calculate_metrics(y_test, y_pred_default)\n",
    "    default_metrics.update({\n",
    "        'Model': model_name,\n",
    "        'Feature_Set': feature_set_name,\n",
    "        'Tuning_Method': 'Default',\n",
    "        'Training_Time': (datetime.now() - start_time).total_seconds(),\n",
    "        'Best_Params': 'Default'\n",
    "    })\n",
    "    results.append(default_metrics)\n",
    "    \n",
    "    # 2. GridSearchCV (if parameters provided)\n",
    "    if grid_params:\n",
    "        print(f\"  Training {model_name} with GridSearchCV...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            model, grid_params, cv=5, scoring='neg_mean_squared_error', \n",
    "            n_jobs=-1, random_state=RANDOM_STATE\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        y_pred_grid = grid_search.predict(X_test)\n",
    "        \n",
    "        grid_metrics = calculate_metrics(y_test, y_pred_grid)\n",
    "        grid_metrics.update({\n",
    "            'Model': model_name,\n",
    "            'Feature_Set': feature_set_name,\n",
    "            'Tuning_Method': 'GridSearch',\n",
    "            'Training_Time': (datetime.now() - start_time).total_seconds(),\n",
    "            'Best_Params': str(grid_search.best_params_)\n",
    "        })\n",
    "        results.append(grid_metrics)\n",
    "    \n",
    "    # 3. RandomizedSearchCV (if parameters provided)\n",
    "    if random_params:\n",
    "        print(f\"  Training {model_name} with RandomizedSearchCV...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            model, random_params, n_iter=50, cv=5, scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1, random_state=RANDOM_STATE\n",
    "        )\n",
    "        random_search.fit(X_train, y_train)\n",
    "        y_pred_random = random_search.predict(X_test)\n",
    "        \n",
    "        random_metrics = calculate_metrics(y_test, y_pred_random)\n",
    "        random_metrics.update({\n",
    "            'Model': model_name,\n",
    "            'Feature_Set': feature_set_name,\n",
    "            'Tuning_Method': 'RandomSearch',\n",
    "            'Training_Time': (datetime.now() - start_time).total_seconds(),\n",
    "            'Best_Params': str(random_search.best_params_)\n",
    "        })\n",
    "        results.append(random_metrics)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Training and evaluation functions defined successfully!\")\n",
    "print(\"Functions include:\")\n",
    "print(\"- calculate_metrics(): Computes RMSE, MAE, R², MAPE, MedAE, Max Error, Explained Variance\")\n",
    "print(\"- train_and_evaluate_model(): Trains models with default, GridSearch, and RandomSearch methods\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2127d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Training Loop - Kitchen Sink Approach\n",
    "print(\"=== STARTING COMPREHENSIVE MODEL TRAINING ===\")\n",
    "print(\"This will train all models with all feature sets and tuning methods...\")\n",
    "print(\"Total combinations: 12 models × 3 feature sets × 3 tuning methods = 108 combinations\")\n",
    "print(\"This may take several minutes to complete...\\n\")\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "total_combinations = len(models_config) * len(feature_sets) * 3  # 3 tuning methods\n",
    "current_combination = 0\n",
    "\n",
    "# Start timing\n",
    "overall_start_time = datetime.now()\n",
    "\n",
    "# Loop through all models\n",
    "for model_name, model_config in models_config.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING MODEL: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model = model_config['model']\n",
    "    grid_params = model_config['grid_params']\n",
    "    random_params = model_config['random_params']\n",
    "    \n",
    "    # Loop through all feature sets\n",
    "    for feature_set_name, (X_train, X_test, feature_names) in feature_sets.items():\n",
    "        print(f\"\\n--- Feature Set: {feature_set_name} ({X_train.shape[1]} features) ---\")\n",
    "        \n",
    "        # Train and evaluate the model\n",
    "        try:\n",
    "            model_results = train_and_evaluate_model(\n",
    "                model, model_name, feature_set_name, \n",
    "                X_train, X_test, y_train, y_test,\n",
    "                grid_params, random_params\n",
    "            )\n",
    "            all_results.extend(model_results)\n",
    "            current_combination += len(model_results)\n",
    "            \n",
    "            print(f\"  ✓ Completed {len(model_results)} tuning methods\")\n",
    "            print(f\"  Progress: {current_combination}/{total_combinations} combinations\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error training {model_name} with {feature_set_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Calculate total time\n",
    "total_time = datetime.now() - overall_start_time\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING COMPLETED!\")\n",
    "print(f\"Total time: {total_time}\")\n",
    "print(f\"Total results: {len(all_results)}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(f\"\\nResults DataFrame shape: {results_df.shape}\")\n",
    "print(f\"Columns: {list(results_df.columns)}\")\n",
    "print(f\"\\nFirst few results:\")\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23dc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Analysis and Model Comparison\n",
    "print(\"=== RESULTS ANALYSIS ===\")\n",
    "\n",
    "# Display comprehensive results\n",
    "print(f\"Total experiments completed: {len(results_df)}\")\n",
    "print(f\"Unique models tested: {results_df['Model'].nunique()}\")\n",
    "print(f\"Feature sets tested: {results_df['Feature_Set'].unique()}\")\n",
    "print(f\"Tuning methods tested: {results_df['Tuning_Method'].unique()}\")\n",
    "\n",
    "# Sort by RMSE (lower is better)\n",
    "results_sorted = results_df.sort_values('RMSE').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n=== TOP 10 BEST MODELS (by RMSE) ===\")\n",
    "top_10 = results_sorted.head(10)\n",
    "for idx, row in top_10.iterrows():\n",
    "    print(f\"{idx+1:2d}. {row['Model']:20s} | {row['Feature_Set']:12s} | {row['Tuning_Method']:12s} | RMSE: {row['RMSE']:8.2f} | R²: {row['R2']:6.3f}\")\n",
    "\n",
    "# Best model overall\n",
    "best_model = results_sorted.iloc[0]\n",
    "print(f\"\\n=== BEST MODEL OVERALL ===\")\n",
    "print(f\"Model: {best_model['Model']}\")\n",
    "print(f\"Feature Set: {best_model['Feature_Set']}\")\n",
    "print(f\"Tuning Method: {best_model['Tuning_Method']}\")\n",
    "print(f\"RMSE: {best_model['RMSE']:.2f}\")\n",
    "print(f\"MAE: {best_model['MAE']:.2f}\")\n",
    "print(f\"R²: {best_model['R2']:.3f}\")\n",
    "print(f\"MAPE: {best_model['MAPE']:.1f}%\")\n",
    "print(f\"Training Time: {best_model['Training_Time']:.2f} seconds\")\n",
    "print(f\"Best Parameters: {best_model['Best_Params']}\")\n",
    "\n",
    "# Analysis by different criteria\n",
    "print(f\"\\n=== ANALYSIS BY DIFFERENT METRICS ===\")\n",
    "\n",
    "# Best by R²\n",
    "best_r2 = results_df.loc[results_df['R2'].idxmax()]\n",
    "print(f\"Best R²: {best_r2['Model']} ({best_r2['Feature_Set']}, {best_r2['Tuning_Method']}) - R²: {best_r2['R2']:.3f}\")\n",
    "\n",
    "# Best by MAE\n",
    "best_mae = results_df.loc[results_df['MAE'].idxmin()]\n",
    "print(f\"Best MAE: {best_mae['Model']} ({best_mae['Feature_Set']}, {best_mae['Tuning_Method']}) - MAE: {best_mae['MAE']:.2f}\")\n",
    "\n",
    "# Best by MAPE\n",
    "best_mape = results_df.loc[results_df['MAPE'].idxmin()]\n",
    "print(f\"Best MAPE: {best_mape['Model']} ({best_mape['Feature_Set']}, {best_mape['Tuning_Method']}) - MAPE: {best_mape['MAPE']:.1f}%\")\n",
    "\n",
    "# Fastest training\n",
    "fastest = results_df.loc[results_df['Training_Time'].idxmin()]\n",
    "print(f\"Fastest Training: {fastest['Model']} ({fastest['Feature_Set']}, {fastest['Tuning_Method']}) - Time: {fastest['Training_Time']:.2f}s\")\n",
    "\n",
    "# Analysis by feature sets\n",
    "print(f\"\\n=== PERFORMANCE BY FEATURE SET ===\")\n",
    "feature_performance = results_df.groupby('Feature_Set').agg({\n",
    "    'RMSE': 'mean',\n",
    "    'R2': 'mean',\n",
    "    'MAE': 'mean',\n",
    "    'MAPE': 'mean'\n",
    "}).round(3)\n",
    "print(feature_performance)\n",
    "\n",
    "# Analysis by tuning method\n",
    "print(f\"\\n=== PERFORMANCE BY TUNING METHOD ===\")\n",
    "tuning_performance = results_df.groupby('Tuning_Method').agg({\n",
    "    'RMSE': 'mean',\n",
    "    'R2': 'mean',\n",
    "    'MAE': 'mean',\n",
    "    'MAPE': 'mean',\n",
    "    'Training_Time': 'mean'\n",
    "}).round(3)\n",
    "print(tuning_performance)\n",
    "\n",
    "# Analysis by model type\n",
    "print(f\"\\n=== PERFORMANCE BY MODEL TYPE ===\")\n",
    "model_performance = results_df.groupby('Model').agg({\n",
    "    'RMSE': 'mean',\n",
    "    'R2': 'mean',\n",
    "    'MAE': 'mean',\n",
    "    'MAPE': 'mean',\n",
    "    'Training_Time': 'mean'\n",
    "}).round(3).sort_values('RMSE')\n",
    "print(model_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94049714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "print(\"=== CREATING COMPREHENSIVE VISUALIZATIONS ===\")\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create a large figure with multiple subplots\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "fig.suptitle('Comprehensive Model Performance Analysis', fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "# 1. RMSE Comparison by Model and Feature Set\n",
    "ax1 = plt.subplot(3, 4, 1)\n",
    "rmse_pivot = results_df.pivot_table(values='RMSE', index='Model', columns='Feature_Set', aggfunc='mean')\n",
    "sns.heatmap(rmse_pivot, annot=True, fmt='.1f', cmap='RdYlBu_r', ax=ax1)\n",
    "ax1.set_title('RMSE by Model and Feature Set')\n",
    "ax1.set_xlabel('Feature Set')\n",
    "ax1.set_ylabel('Model')\n",
    "\n",
    "# 2. R² Comparison by Model and Feature Set\n",
    "ax2 = plt.subplot(3, 4, 2)\n",
    "r2_pivot = results_df.pivot_table(values='R2', index='Model', columns='Feature_Set', aggfunc='mean')\n",
    "sns.heatmap(r2_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=ax2)\n",
    "ax2.set_title('R² by Model and Feature Set')\n",
    "ax2.set_xlabel('Feature Set')\n",
    "ax2.set_ylabel('Model')\n",
    "\n",
    "# 3. Top 10 Models by RMSE\n",
    "ax3 = plt.subplot(3, 4, 3)\n",
    "top_10_models = results_sorted.head(10)\n",
    "bars = ax3.barh(range(len(top_10_models)), top_10_models['RMSE'])\n",
    "ax3.set_yticks(range(len(top_10_models)))\n",
    "ax3.set_yticklabels([f\"{row['Model']}\\n({row['Feature_Set']}, {row['Tuning_Method']})\" \n",
    "                     for _, row in top_10_models.iterrows()], fontsize=8)\n",
    "ax3.set_xlabel('RMSE')\n",
    "ax3.set_title('Top 10 Models by RMSE')\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# 4. Training Time vs Performance\n",
    "ax4 = plt.subplot(3, 4, 4)\n",
    "scatter = ax4.scatter(results_df['Training_Time'], results_df['RMSE'], \n",
    "                     c=results_df['R2'], cmap='viridis', alpha=0.6, s=50)\n",
    "ax4.set_xlabel('Training Time (seconds)')\n",
    "ax4.set_ylabel('RMSE')\n",
    "ax4.set_title('Training Time vs RMSE\\n(Color = R²)')\n",
    "plt.colorbar(scatter, ax=ax4, label='R²')\n",
    "\n",
    "# 5. Performance by Tuning Method\n",
    "ax5 = plt.subplot(3, 4, 5)\n",
    "tuning_metrics = results_df.groupby('Tuning_Method')[['RMSE', 'R2', 'MAE']].mean()\n",
    "tuning_metrics.plot(kind='bar', ax=ax5)\n",
    "ax5.set_title('Average Performance by Tuning Method')\n",
    "ax5.set_xlabel('Tuning Method')\n",
    "ax5.set_ylabel('Metric Value')\n",
    "ax5.legend()\n",
    "ax5.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Performance by Feature Set\n",
    "ax6 = plt.subplot(3, 4, 6)\n",
    "feature_metrics = results_df.groupby('Feature_Set')[['RMSE', 'R2', 'MAE']].mean()\n",
    "feature_metrics.plot(kind='bar', ax=ax6)\n",
    "ax6.set_title('Average Performance by Feature Set')\n",
    "ax6.set_xlabel('Feature Set')\n",
    "ax6.set_ylabel('Metric Value')\n",
    "ax6.legend()\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 7. Model Performance Distribution\n",
    "ax7 = plt.subplot(3, 4, 7)\n",
    "model_rmse = results_df.groupby('Model')['RMSE'].mean().sort_values()\n",
    "ax7.barh(range(len(model_rmse)), model_rmse.values)\n",
    "ax7.set_yticks(range(len(model_rmse)))\n",
    "ax7.set_yticklabels(model_rmse.index, fontsize=9)\n",
    "ax7.set_xlabel('Average RMSE')\n",
    "ax7.set_title('Average RMSE by Model')\n",
    "ax7.invert_yaxis()\n",
    "\n",
    "# 8. MAPE Distribution\n",
    "ax8 = plt.subplot(3, 4, 8)\n",
    "ax8.hist(results_df['MAPE'], bins=20, alpha=0.7, edgecolor='black')\n",
    "ax8.set_xlabel('MAPE (%)')\n",
    "ax8.set_ylabel('Frequency')\n",
    "ax8.set_title('MAPE Distribution')\n",
    "ax8.axvline(results_df['MAPE'].mean(), color='red', linestyle='--', \n",
    "           label=f'Mean: {results_df[\"MAPE\"].mean():.1f}%')\n",
    "ax8.legend()\n",
    "\n",
    "# 9. R² vs RMSE Scatter\n",
    "ax9 = plt.subplot(3, 4, 9)\n",
    "scatter = ax9.scatter(results_df['RMSE'], results_df['R2'], \n",
    "                     c=results_df['Training_Time'], cmap='plasma', alpha=0.6, s=50)\n",
    "ax9.set_xlabel('RMSE')\n",
    "ax9.set_ylabel('R²')\n",
    "ax9.set_title('R² vs RMSE\\n(Color = Training Time)')\n",
    "plt.colorbar(scatter, ax=ax9, label='Training Time (s)')\n",
    "\n",
    "# 10. Best Model Performance by Metric\n",
    "ax10 = plt.subplot(3, 4, 10)\n",
    "best_metrics = ['RMSE', 'MAE', 'MAPE', 'R2', 'Explained_Variance']\n",
    "best_values = []\n",
    "for metric in best_metrics:\n",
    "    if metric in ['RMSE', 'MAE', 'MAPE']:\n",
    "        best_idx = results_df[metric].idxmin()\n",
    "    else:\n",
    "        best_idx = results_df[metric].idxmax()\n",
    "    best_values.append(results_df.loc[best_idx, metric])\n",
    "\n",
    "bars = ax10.bar(best_metrics, best_values, color=['red', 'orange', 'yellow', 'green', 'blue'])\n",
    "ax10.set_title('Best Performance by Metric')\n",
    "ax10.set_ylabel('Metric Value')\n",
    "ax10.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 11. Feature Set Comparison\n",
    "ax11 = plt.subplot(3, 4, 11)\n",
    "feature_comparison = results_df.groupby('Feature_Set')[['RMSE', 'R2', 'MAE', 'MAPE']].mean()\n",
    "feature_comparison.plot(kind='bar', ax=ax11, width=0.8)\n",
    "ax11.set_title('Feature Set Comparison')\n",
    "ax11.set_xlabel('Feature Set')\n",
    "ax11.set_ylabel('Average Metric Value')\n",
    "ax11.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax11.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 12. Model Complexity vs Performance\n",
    "ax12 = plt.subplot(3, 4, 12)\n",
    "# Create a complexity score based on training time\n",
    "complexity_score = results_df['Training_Time'] / results_df['Training_Time'].max()\n",
    "ax12.scatter(complexity_score, results_df['RMSE'], \n",
    "            c=results_df['R2'], cmap='coolwarm', alpha=0.6, s=50)\n",
    "ax12.set_xlabel('Model Complexity (Normalized Training Time)')\n",
    "ax12.set_ylabel('RMSE')\n",
    "ax12.set_title('Model Complexity vs Performance\\n(Color = R²)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualizations completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90510b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model Analysis and Feature Importance\n",
    "print(\"=== BEST MODEL DEEP DIVE ANALYSIS ===\")\n",
    "\n",
    "# Get the best model configuration\n",
    "best_model_name = best_model['Model']\n",
    "best_feature_set = best_model['Feature_Set']\n",
    "best_tuning_method = best_model['Tuning_Method']\n",
    "\n",
    "print(f\"Analyzing best model: {best_model_name}\")\n",
    "print(f\"Feature set: {best_feature_set}\")\n",
    "print(f\"Tuning method: {best_tuning_method}\")\n",
    "\n",
    "# Retrain the best model to get feature importance and detailed analysis\n",
    "best_model_config = models_config[best_model_name]\n",
    "best_model_instance = best_model_config['model']\n",
    "\n",
    "# Get the appropriate feature set\n",
    "X_train_best, X_test_best, feature_names_best = feature_sets[best_feature_set]\n",
    "\n",
    "# Retrain with best parameters\n",
    "if best_tuning_method == 'Default':\n",
    "    final_model = best_model_instance.__class__(**best_model_instance.get_params())\n",
    "    final_model.fit(X_train_best, y_train)\n",
    "    best_params = 'Default'\n",
    "    \n",
    "elif best_tuning_method == 'GridSearch':\n",
    "    grid_search = GridSearchCV(\n",
    "        best_model_instance, best_model_config['grid_params'], \n",
    "        cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=RANDOM_STATE\n",
    "    )\n",
    "    grid_search.fit(X_train_best, y_train)\n",
    "    final_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "elif best_tuning_method == 'RandomSearch':\n",
    "    random_search = RandomizedSearchCV(\n",
    "        best_model_instance, best_model_config['random_params'], \n",
    "        n_iter=50, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=RANDOM_STATE\n",
    "    )\n",
    "    random_search.fit(X_train_best, y_train)\n",
    "    final_model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_best = final_model.predict(X_test_best)\n",
    "\n",
    "print(f\"\\nBest parameters: {best_params}\")\n",
    "\n",
    "# Feature importance analysis (for tree-based models)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    print(f\"\\n=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names_best,\n",
    "        'importance': final_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    for idx, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"{row['feature']:25s}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "elif hasattr(final_model, 'coef_'):\n",
    "    print(f\"\\n=== COEFFICIENT ANALYSIS ===\")\n",
    "    if len(final_model.coef_.shape) == 1:\n",
    "        coefficients = pd.DataFrame({\n",
    "            'feature': feature_names_best,\n",
    "            'coefficient': final_model.coef_\n",
    "        }).sort_values('coefficient', key=abs, ascending=False)\n",
    "        \n",
    "        print(\"Top 10 Most Important Features (by coefficient magnitude):\")\n",
    "        for idx, row in coefficients.head(10).iterrows():\n",
    "            print(f\"{row['feature']:25s}: {row['coefficient']:.4f}\")\n",
    "        \n",
    "        # Plot coefficients\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_coefs = coefficients.head(15)\n",
    "        colors = ['red' if x < 0 else 'blue' for x in top_coefs['coefficient']]\n",
    "        plt.barh(range(len(top_coefs)), top_coefs['coefficient'], color=colors)\n",
    "        plt.yticks(range(len(top_coefs)), top_coefs['feature'])\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        plt.title(f'Feature Coefficients - {best_model_name}')\n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Actual vs Predicted Analysis\n",
    "print(f\"\\n=== ACTUAL VS PREDICTED ANALYSIS ===\")\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 1. Actual vs Predicted Scatter Plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Sales Qty')\n",
    "plt.ylabel('Predicted Sales Qty')\n",
    "plt.title(f'Actual vs Predicted\\n{best_model_name}')\n",
    "\n",
    "# Add R² to the plot\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "plt.text(0.05, 0.95, f'R² = {r2_best:.3f}', transform=plt.gca().transAxes, \n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 2. Residuals Plot\n",
    "plt.subplot(1, 3, 2)\n",
    "residuals = y_test - y_pred_best\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Sales Qty')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot')\n",
    "\n",
    "# 3. Residuals Distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(residuals, bins=10, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residuals Distribution')\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed performance metrics\n",
    "print(f\"\\n=== DETAILED PERFORMANCE METRICS ===\")\n",
    "detailed_metrics = calculate_metrics(y_test, y_pred_best)\n",
    "for metric, value in detailed_metrics.items():\n",
    "    if metric == 'MAPE':\n",
    "        print(f\"{metric}: {value:.1f}%\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "\n",
    "# Prediction accuracy by range\n",
    "print(f\"\\n=== PREDICTION ACCURACY BY SALES RANGE ===\")\n",
    "test_ranges = pd.cut(y_test, bins=3, labels=['Low', 'Medium', 'High'])\n",
    "range_accuracy = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_best,\n",
    "    'Range': test_ranges\n",
    "})\n",
    "\n",
    "for range_name in ['Low', 'Medium', 'High']:\n",
    "    range_data = range_accuracy[range_accuracy['Range'] == range_name]\n",
    "    if len(range_data) > 0:\n",
    "        range_mae = mean_absolute_error(range_data['Actual'], range_data['Predicted'])\n",
    "        range_mape = np.mean(np.abs((range_data['Actual'] - range_data['Predicted']) / \n",
    "                                   np.maximum(np.abs(range_data['Actual']), 1e-8))) * 100\n",
    "        print(f\"{range_name:6s} Sales: MAE = {range_mae:.1f}, MAPE = {range_mape:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3287ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Predictions and Summary\n",
    "print(\"=== FINAL PREDICTIONS AND SUMMARY ===\")\n",
    "\n",
    "# Create comprehensive predictions table\n",
    "predictions_df = pd.DataFrame({\n",
    "    'YearMonth': test_eng['YearMonth'],\n",
    "    'Actual_Sales_Qty': y_test,\n",
    "    'Predicted_Sales_Qty': y_pred_best,\n",
    "    'Error': y_test - y_pred_best,\n",
    "    'Absolute_Error': np.abs(y_test - y_pred_best),\n",
    "    'Percentage_Error': ((y_test - y_pred_best) / np.maximum(np.abs(y_test), 1e-8)) * 100\n",
    "})\n",
    "\n",
    "print(\"=== FINAL PREDICTIONS ON TEST SET ===\")\n",
    "print(predictions_df.round(2))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== PREDICTION SUMMARY STATISTICS ===\")\n",
    "print(f\"Mean Absolute Error: {predictions_df['Absolute_Error'].mean():.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error: {predictions_df['Percentage_Error'].abs().mean():.1f}%\")\n",
    "print(f\"Root Mean Square Error: {np.sqrt(np.mean(predictions_df['Error']**2)):.2f}\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred_best):.3f}\")\n",
    "\n",
    "# Best and worst predictions\n",
    "print(f\"\\n=== BEST AND WORST PREDICTIONS ===\")\n",
    "best_pred_idx = predictions_df['Absolute_Error'].abs().idxmin()\n",
    "worst_pred_idx = predictions_df['Absolute_Error'].abs().idxmax()\n",
    "\n",
    "print(f\"Best prediction (smallest error):\")\n",
    "print(f\"  Date: {predictions_df.loc[best_pred_idx, 'YearMonth']}\")\n",
    "print(f\"  Actual: {predictions_df.loc[best_pred_idx, 'Actual_Sales_Qty']:.1f}\")\n",
    "print(f\"  Predicted: {predictions_df.loc[best_pred_idx, 'Predicted_Sales_Qty']:.1f}\")\n",
    "print(f\"  Error: {predictions_df.loc[best_pred_idx, 'Error']:.1f}\")\n",
    "\n",
    "print(f\"\\nWorst prediction (largest error):\")\n",
    "print(f\"  Date: {predictions_df.loc[worst_pred_idx, 'YearMonth']}\")\n",
    "print(f\"  Actual: {predictions_df.loc[worst_pred_idx, 'Actual_Sales_Qty']:.1f}\")\n",
    "print(f\"  Predicted: {predictions_df.loc[worst_pred_idx, 'Predicted_Sales_Qty']:.1f}\")\n",
    "print(f\"  Error: {predictions_df.loc[worst_pred_idx, 'Error']:.1f}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('regression_model_results.csv', index=False)\n",
    "predictions_df.to_csv('final_predictions.csv', index=False)\n",
    "\n",
    "print(f\"\\n=== RESULTS SAVED ===\")\n",
    "print(f\"Model comparison results saved to: regression_model_results.csv\")\n",
    "print(f\"Final predictions saved to: final_predictions.csv\")\n",
    "\n",
    "# Final model summary\n",
    "print(f\"\\n=== FINAL MODEL SUMMARY ===\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Feature Set: {best_feature_set}\")\n",
    "print(f\"Tuning Method: {best_tuning_method}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Test Set Performance:\")\n",
    "print(f\"  RMSE: {detailed_metrics['RMSE']:.2f}\")\n",
    "print(f\"  MAE: {detailed_metrics['MAE']:.2f}\")\n",
    "print(f\"  R²: {detailed_metrics['R2']:.3f}\")\n",
    "print(f\"  MAPE: {detailed_metrics['MAPE']:.1f}%\")\n",
    "print(f\"  Explained Variance: {detailed_metrics['Explained_Variance']:.3f}\")\n",
    "\n",
    "# Model recommendations\n",
    "print(f\"\\n=== MODEL RECOMMENDATIONS ===\")\n",
    "print(f\"1. Best Overall Model: {best_model_name} with {best_feature_set} features\")\n",
    "print(f\"2. Best R² Score: {best_r2['Model']} ({best_r2['Feature_Set']}, {best_r2['Tuning_Method']}) - R²: {best_r2['R2']:.3f}\")\n",
    "print(f\"3. Fastest Training: {fastest['Model']} ({fastest['Feature_Set']}, {fastest['Tuning_Method']}) - Time: {fastest['Training_Time']:.2f}s\")\n",
    "print(f\"4. Most Accurate (Lowest MAPE): {best_mape['Model']} ({best_mape['Feature_Set']}, {best_mape['Tuning_Method']}) - MAPE: {best_mape['MAPE']:.1f}%\")\n",
    "\n",
    "# Feature engineering insights\n",
    "print(f\"\\n=== FEATURE ENGINEERING INSIGHTS ===\")\n",
    "feature_performance_sorted = feature_performance.sort_values('RMSE')\n",
    "print(\"Feature set performance (best to worst by RMSE):\")\n",
    "for idx, (feature_set, metrics) in enumerate(feature_performance_sorted.iterrows(), 1):\n",
    "    print(f\"{idx}. {feature_set}: RMSE={metrics['RMSE']:.2f}, R²={metrics['R2']:.3f}\")\n",
    "\n",
    "# Hyperparameter tuning insights\n",
    "print(f\"\\n=== HYPERPARAMETER TUNING INSIGHTS ===\")\n",
    "tuning_performance_sorted = tuning_performance.sort_values('RMSE')\n",
    "print(\"Tuning method performance (best to worst by RMSE):\")\n",
    "for idx, (tuning_method, metrics) in enumerate(tuning_performance_sorted.iterrows(), 1):\n",
    "    print(f\"{idx}. {tuning_method}: RMSE={metrics['RMSE']:.2f}, R²={metrics['R2']:.3f}, Time={metrics['Training_Time']:.2f}s\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"REGRESSION ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total models tested: {len(models_config)}\")\n",
    "print(f\"Total experiments: {len(results_df)}\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Best performance: RMSE={detailed_metrics['RMSE']:.2f}, R²={detailed_metrics['R2']:.3f}\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1ce1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
